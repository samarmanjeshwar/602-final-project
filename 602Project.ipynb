{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "602Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us-69MbAbv2u",
        "colab_type": "text"
      },
      "source": [
        "Project content:\n",
        "\n",
        "\n",
        "1.   Train first model on digits dataset\n",
        "2.   Train second model on alphabet dataset\n",
        "\n",
        "I will be using the same model structure for both models and note the differences if any.\n",
        "\n",
        "For the first model, I will be using a project by Yassine Ghouzam as a reference.\n",
        "\n",
        "For the second model, I will be using the data set provided by Yair Hadad.\n",
        "\n",
        "Reference project 1: https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6\n",
        "\n",
        "Reference project 2: https://www.kaggle.com/yairhadad1/cnn-for-handwritten-alphabets\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpVPXW5KdxCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "45b18f61-18ea-4f29-d459-bb783ab6115b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_gRyNqvODkv",
        "colab_type": "text"
      },
      "source": [
        "Train and test datasets for the first model are read from files store on my google drive.  The drive is mounted on this notebook for easy access."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g0pLRYCl-qj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"drive/My Drive/Colab Notebooks/602Project/train.csv\")\n",
        "test = pd.read_csv(\"drive/My Drive/Colab Notebooks/602Project/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmWFEGusnO_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "13b0a363-3a2b-44df-c47d-aec641da0aa5"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      1       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      1       0       0       0  ...         0         0         0         0\n",
              "3      4       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUAC3xvlP9v-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2413db84-c5d1-405f-da83-33aa21cb53a1"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42000, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3i3ejCAO3kQ",
        "colab_type": "text"
      },
      "source": [
        "X_train and Y_train variables are initialized.\n",
        "\n",
        "Y_train is the set of target labels that is derived from the 'label' feature of the train dataset\n",
        "\n",
        "X_train is derived from the remaining features of the train dataset.\n",
        "\n",
        "Each feature is a pixel value.  There are a total of 784 pixels per image. (28 X 28)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycSeioZgnRjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = train[\"label\"]\n",
        "X_train = train.drop(labels = [\"label\"],axis = 1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WvJ_CDAnuyS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "4ada2fc4-5773-46fa-b7c9-014a65227079"
      },
      "source": [
        "sns.countplot(Y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7feb9ac6a550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EnUTjEVRc9B",
        "colab_type": "text"
      },
      "source": [
        "Check the data for null or missing values values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBUQdyyG0MpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c561906e-d2a0-4d8b-f4f2-fcad48df556d"
      },
      "source": [
        "# Check the data\n",
        "X_train.isnull().any().describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count       784\n",
              "unique        1\n",
              "top       False\n",
              "freq        784\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfnW0UaD0TpC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "138bc839-6990-4d7a-f83d-1a8520a7d4b2"
      },
      "source": [
        "test.isnull().any().describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count       784\n",
              "unique        1\n",
              "top       False\n",
              "freq        784\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u1HA90OTUOu",
        "colab_type": "text"
      },
      "source": [
        "Pixel values are normally between 0 and 255 (for greyscale images).  We scale it to values between 0 and 1 to help achieve faster convergance of our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viNjJjANn0Gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize the data\n",
        "X_train = X_train / 255.0\n",
        "test = test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNULpHG_TrzP",
        "colab_type": "text"
      },
      "source": [
        "Convert each record of data into a 28 X 28 matrix. (28 X 28 X 1) since it is greyscale and there are no additional RGB colour layers.  If it were to be coloured, we would have a matrix of 28 X 28 X 3. \n",
        "\n",
        "CNN works on inputs that are in matrix format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj46az_psLCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
        "X_train = X_train.values.reshape(-1,28,28,1)\n",
        "test = test.values.reshape(-1,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7z4rCN2UbYs",
        "colab_type": "text"
      },
      "source": [
        "Convert the vector into a binary class matrix with values from 1 to 10 (for the 10 digits that are labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZIzozyIshSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = to_categorical(Y_train, num_classes = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lT4iUV1VYpp",
        "colab_type": "text"
      },
      "source": [
        "Create a train-test split on the X_train dataset (and the Y_train dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YwPehGOslV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_seed = 2\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVQ0r5eAVzCq",
        "colab_type": "text"
      },
      "source": [
        "Plot the image at index 0.  As you can see, the image at the first index is 5.  Y_train[0] stores a list of probabilities of what the image could be.  The 6th index corresponds to the value '5'.\n",
        "\n",
        "X_train[0][ :, :, 0] takes the first index of X_train, the entire range of pixels from the first 2 dimensions and the first and only colour channel (0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbdExZJWsoOK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "45c88594-604b-45e8-ca47-43fbc6d85961"
      },
      "source": [
        "g = plt.imshow(X_train[0][:,:,0])\n",
        "print(Y_train[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYcOQ2MaWwM1",
        "colab_type": "text"
      },
      "source": [
        "Now we define our model.\n",
        "\n",
        "I have chosen to work with a CNN model as I feel it is best suited towards image processing.\n",
        "\n",
        "It is a sequential model.\n",
        "\n",
        "The layers are defined as follows:\n",
        "\n",
        "\n",
        "*   2D convolutional layer.  The filter uses \"same\" padding.  This means that the dimension of the data is maintained and no data is lost while propogating through this layer.  I have chosen \"relu\" (rectified linear unit) as it's activation function.  This layer has a set of 32 filter associated with it.  The kernal size I have selected is 5 X 5.  \n",
        "\n",
        "There are two convolutional layers back to back\n",
        "*    MaxPool layer.  This layer acts a a downsampling filter.It takes the maximum values from different regions of the input and returns an output with those values.  The output intentionally has a lower number of dimensions as compared to the input.  this is a measure to reduce overfitting.\n",
        "\n",
        "\n",
        "*   Dropout layer.  This layer is used for regularization.  This layer randomly ignores certain nodes. in each training sample.  this forces the network to learn features in a distributed way.  this layer is quite useful when it comes to processing handwritten integers because everyone has a different style of writing.\n",
        "\n",
        "*   The above structure is repeated again with smaller kernels.\n",
        "\n",
        "\n",
        "*   Flatten layer.  This layer converts the final feature map into a 1-D vector.  The output of this layer can then be passed to a fully connected layer to make predictions.\n",
        "\n",
        "\n",
        "*   Dense layer.  The last two dense layers behave like a simple artificial neral network (ANN).  the first one uses a 'relu' activation function and the second one uses a 'softmax' activation function.  The softmax function is used because we have 10 different probability values that we need to predict.  If it was just two, I cold have also used a sigmoid function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0Vjv1qbsuQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (28,28,1)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation = \"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkIP8n1JI6Us",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "3f67d294-f34a-4bda-e833-0134ef57f6a8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        25632     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               803072    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 887,530\n",
            "Trainable params: 887,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_bIMMQfdB4M",
        "colab_type": "text"
      },
      "source": [
        "Compile the model using an 'adam' optimizer.  The loss function selected is 'categorical cross entropy'.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzpZiLdCI8D8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJG50Tj_gEAJ",
        "colab_type": "text"
      },
      "source": [
        "Data Augmentation:\n",
        "\n",
        "In this step, we modify our input data so that our model's performance is boosted.  Modifying data could be doe by expanding the image, inverting the image, darkening the image adding brightness to the image etc.\n",
        "\n",
        "This is usually done when our training data set is limited.\n",
        "\n",
        "In the real world, our eye is able to tell what number we are looking at regardless of whether it is inverted or not.  Data augmentation helps our model come a little closer to doing that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usiFrBsExA9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "datagen.fit(X_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs7S3Q3IRZ1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1\n",
        "batch_size = 86"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EukFtfVVhaaZ",
        "colab_type": "text"
      },
      "source": [
        "The learning rate reduction algorithm decreases the LR every epoch.  In case it is on a plateu, the ReduceOnPlateau method reduces the LR by half (factor) if accuracy isn't imporved within 3 epochs (patience)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnQFJQ3pSHd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvGBFBt8irHP",
        "colab_type": "text"
      },
      "source": [
        "Now we train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf1gXe5CB9W1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7a3abfae-c8e4-4599-a92c-a58dd944e423"
      },
      "source": [
        "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
        "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
        "                              , callbacks=[learning_rate_reduction])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " - 260s - loss: 0.4161 - accuracy: 0.8648 - val_loss: 0.0672 - val_accuracy: 0.9807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlQTKmrviKdw",
        "colab_type": "text"
      },
      "source": [
        "Now I prepare the handwritten alphabet dataset.  The labels are integers (0 -> 25).  I need to convert them into alphabets.\n",
        "\n",
        "The dataset was obtained from the notebook belonging to Yair Hadad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIZ0f9IGU8rC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"drive/My Drive/Colab Notebooks/602Project/A_Z Handwritten Data.csv\").astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bBpQF7npLeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.rename(columns={'0':'label'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xq3XPImha5u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "179b9505-5633-4fdb-e2c0-089eaf0f8780"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>0.10</th>\n",
              "      <th>0.11</th>\n",
              "      <th>0.12</th>\n",
              "      <th>0.13</th>\n",
              "      <th>0.14</th>\n",
              "      <th>0.15</th>\n",
              "      <th>0.16</th>\n",
              "      <th>0.17</th>\n",
              "      <th>0.18</th>\n",
              "      <th>0.19</th>\n",
              "      <th>0.20</th>\n",
              "      <th>0.21</th>\n",
              "      <th>0.22</th>\n",
              "      <th>0.23</th>\n",
              "      <th>0.24</th>\n",
              "      <th>0.25</th>\n",
              "      <th>0.26</th>\n",
              "      <th>0.27</th>\n",
              "      <th>0.28</th>\n",
              "      <th>0.29</th>\n",
              "      <th>0.30</th>\n",
              "      <th>0.31</th>\n",
              "      <th>0.32</th>\n",
              "      <th>0.33</th>\n",
              "      <th>0.34</th>\n",
              "      <th>0.35</th>\n",
              "      <th>0.36</th>\n",
              "      <th>0.37</th>\n",
              "      <th>0.38</th>\n",
              "      <th>0.39</th>\n",
              "      <th>...</th>\n",
              "      <th>0.609</th>\n",
              "      <th>0.610</th>\n",
              "      <th>0.611</th>\n",
              "      <th>0.612</th>\n",
              "      <th>0.613</th>\n",
              "      <th>0.614</th>\n",
              "      <th>0.615</th>\n",
              "      <th>0.616</th>\n",
              "      <th>0.617</th>\n",
              "      <th>0.618</th>\n",
              "      <th>0.619</th>\n",
              "      <th>0.620</th>\n",
              "      <th>0.621</th>\n",
              "      <th>0.622</th>\n",
              "      <th>0.623</th>\n",
              "      <th>0.624</th>\n",
              "      <th>0.625</th>\n",
              "      <th>0.626</th>\n",
              "      <th>0.627</th>\n",
              "      <th>0.628</th>\n",
              "      <th>0.629</th>\n",
              "      <th>0.630</th>\n",
              "      <th>0.631</th>\n",
              "      <th>0.632</th>\n",
              "      <th>0.633</th>\n",
              "      <th>0.634</th>\n",
              "      <th>0.635</th>\n",
              "      <th>0.636</th>\n",
              "      <th>0.637</th>\n",
              "      <th>0.638</th>\n",
              "      <th>0.639</th>\n",
              "      <th>0.640</th>\n",
              "      <th>0.641</th>\n",
              "      <th>0.642</th>\n",
              "      <th>0.643</th>\n",
              "      <th>0.644</th>\n",
              "      <th>0.645</th>\n",
              "      <th>0.646</th>\n",
              "      <th>0.647</th>\n",
              "      <th>0.648</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  0.1  0.2  0.3  0.4  0.5  ...  0.643  0.644  0.645  0.646  0.647  0.648\n",
              "0     A  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0\n",
              "1     A  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0\n",
              "2     A  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0\n",
              "3     A  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0\n",
              "4     A  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKmMwspfewGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop('label',axis = 1)\n",
        "y = df['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhCpWqS7aYs7",
        "colab_type": "text"
      },
      "source": [
        "The original labels are integers from 0 -> 25.  To make it easier for the end user to read and understand, I am mapping them to the alphabets that they correspond to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F-ZEnMI678M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphabets_mapper = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',\n",
        "                    9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',\n",
        "                    17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X',24:'Y',25:'Z'}\n",
        "\n",
        "df[\"label\"] = df[\"label\"].map(alphabets_mapper) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPidc4c4aoJa",
        "colab_type": "text"
      },
      "source": [
        "I am using the same model as the hand-drawn integer dataset.  I want to compare the differences in using the same model on two datasets.  the only difference between them is that the last dense layer has an output of a vector of length 26 with probablilities of what alphabet it might be."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd4D-Alyf77f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (28,28,1)))\n",
        "model2.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model2.add(MaxPool2D(pool_size=(2,2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model2.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model2.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model2.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(256, activation = \"relu\"))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(26, activation = \"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpJr_p8nbAZS",
        "colab_type": "text"
      },
      "source": [
        "Splitting of dataset into train and test sub sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVltBHFq6PLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBmdmJdcbGo3",
        "colab_type": "text"
      },
      "source": [
        "MinMAxScaler to scale pixel values to the range (0,1).  this is done to help achieve convergence faster.\n",
        "\n",
        "Both test and train feature dataset is transformed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWwYuHgn6rde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "standard_scaler = MinMaxScaler()\n",
        "standard_scaler.fit(X_train)\n",
        "\n",
        "X_train = standard_scaler.transform(X_train)\n",
        "X_test = standard_scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEKGPHyahX-u",
        "colab_type": "text"
      },
      "source": [
        "Reshape the datasets into a 28 28 X 1 matrix (since it is greyscale)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ1KcV2j7K3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp5D4SYyseuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s497sywPn0XW",
        "colab_type": "text"
      },
      "source": [
        "Convert label to a binary class matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW4EhA-E7SNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TJ5aozVpoP4",
        "colab_type": "text"
      },
      "source": [
        "The same optimizer and loss function as the first model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeThAOxB6vDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxROLxAe668B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a2f908cf-6b8e-40b7-d4fa-703376d42e53"
      },
      "source": [
        "history = model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=200, verbose=2)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 279337 samples, validate on 93113 samples\n",
            "Epoch 1/2\n",
            " - 1915s - loss: 0.2431 - accuracy: 0.9314 - val_loss: 0.0614 - val_accuracy: 0.9838\n",
            "Epoch 2/2\n",
            " - 1917s - loss: 0.0850 - accuracy: 0.9770 - val_loss: 0.0439 - val_accuracy: 0.9881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7qSXOh6KFXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model2.predict(X_test[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0drgm-19xntZ",
        "colab_type": "text"
      },
      "source": [
        "Predict the values of the X_test feature dataset.\n",
        "\n",
        "preds is a list of output vectors from model2.  As stated before. the vectors contain probabilities of what the input could be.  The example above contains the alphabet 'p'.  The 16th index has a value of almost 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLkGdHkqKymP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "e58c129a-8e2d-4cbd-c719-ac1dda046e79"
      },
      "source": [
        "plt.imshow(X_test[0].reshape(28,28))\n",
        "preds[0]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.1163123e-08, 5.4210169e-08, 1.2277167e-06, 6.1133443e-10,\n",
              "       4.2160263e-08, 4.2440771e-09, 5.7452918e-09, 7.1728712e-10,\n",
              "       1.6524700e-14, 9.6117580e-13, 1.1431513e-10, 5.1582427e-10,\n",
              "       3.5075062e-10, 7.0992807e-09, 7.9410611e-08, 9.9999130e-01,\n",
              "       7.3555519e-08, 7.1130758e-06, 3.4752457e-08, 7.3943540e-10,\n",
              "       4.6180833e-13, 5.4941471e-14, 3.3614225e-13, 1.6297089e-13,\n",
              "       8.1795137e-10, 1.8888429e-11], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9Bp49mQrzQi",
        "colab_type": "text"
      },
      "source": [
        "Conclusion:\n",
        "\n",
        "The same model structure was used on two different datasets.  Both managed to achieve 98% accurracy.  The only modification to the model structure that was required was changing the length of the output vector to 26 to correspond to the 26 letters of the english language.\n",
        "\n",
        "Coming from a hardcore software engineering background, I was used to building architectures specifically catered to the input data that the system would recieve.  It was interesting to find that the same structure could be used to train a model with two completely different input datasets, with minimal modifications. "
      ]
    }
  ]
}